<header>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</header>

# Mod√®le de repr√©sentation de textes pour un prototype de recommandation: m√©thodologie et ing√©nierie

J'ai cr√©√© un prototype de recommandation de films sur base de transformers. Le titre de ma maquette [Canap' is all you need](https://huggingface.co/spaces/mnemlaghi/canap) est un clin d'oeil/hommage appuy√© √† l'article fondateur des m√©canismes d'attention [Attention is all you need](https://arxiv.org/abs/1706.03762). J'√©voque ici les diff√©rents mod√®les utilis√©s ainsi que quelques pistes d'exploitation.

## Principes m√©thodologiques

Les mod√®les de recommandation bas√©s sur le contenu textuel se basent sur des mod√®les de repr√©sentation des textes. Concr√®tement,  un utilisateur rentre une requ√™te courte comme une s√©quence de mots-cl√©s. Cette requ√™te est projet√©e (_encod√©e_) dans un espace de repr√©sentation au sein duquel nous pouvons effectuer des op√©rations alg√©brique: ainsi, la projection de cette requ√™te est compar√©e avec les encodages de descriptifs de contenus. Cette m√©thode de comparaison donne un scoring final, qui va trier les contenus en fonction de leur similarit√© √† la requ√™te.

### Espaces de repr√©sentation

L'espace de repr√©sentation sert √† calculer un score de similarit√© entre la requ√™te et chacun des contenus. Le choix d'un tel espace de repr√©sentation est donc crucial en ce qui concerne la qualit√© de la recommandation subs√©quente. Formellement, si l'on a une suite de documents \\(( t_1, ...t_N)\\) issus d'un ensemble de documents que l'on souhaite comparer √† une requ√™te $q$ introduite par un utilisateur.

Le but du ranking est d'ordonner $N$ scores $s_i$, calcul√©s via la d√©marche suivante:

 * les documents et la requ√™te sont projet√©s dans un espace euclidien, i.e. une fonction $e_{\theta}$ qui projette les textes dans un espace hilbertien $\mathbf{R}^d$, o√π $d$ est la dimension de l'espace et $\theta$ un ensemble de param√®tres caract√©risant la projection $e$ :

 * Munis de cette projection $e$, nous pouvons calculer les scores suivants et d'un op√©rateur $<., .>$ :

$$ <.,.> : \mathbf{R}^d \times \mathbf{R}^d¬†\rightarrow \mathbf{R} $$
$$ \forall i \in [[1,N]], s_i = <e_{\theta}(t_i), e_{\theta}(q)> $$

* L'op√©rateur $<.,.>$  peut √™tre un op√©rateur comme le produit scalaire, la similarit√© cosine, etc. 

L'ensemble $\theta$ de param√®tres peut √™tre appris via de l'apprentissage supervis√©

Nous proposons ici de comparer 3 types d'espace de repr√©sentation.

###¬†Les espaces de repr√©sentation sparse

Une m√©thode sparse : le scoring est effectu√© √† l'aide d'un espace de repr√©sentation _sparse_. Concr√®tement, nous proposons un ranking via les fr√©quences et les occurrences des mots contenus dans la requ√™te et les descriptifs. L'espace de projection $d$ est √©quivalent √† la cardinalit√© $V$ du vocabulaire (d'un ordre de grandeur se situant entre 10 000 et 1 000 000). Dans la maquette, nous avons choisi [TF IDF](https://fr.wikipedia.org/wiki/TF-IDF) avec prise en compte des bigrammes et filtrage des mots dont la fr√©quence est inf√©rieure √† 3.

### Les m√©thodes denses

Ici, l'espace de repr√©sentation est obtenu pour effectuer des op√©rations sur des aspects s√©mantiques (li√©s au sens des mots), plut√¥t que fr√©quentiels (li√©s aux occurrences strictes des mots). L'espace de repr√©sentation est ici appel√© un embedding, car il repr√©sente une s√©quence dans un espace de dimension $d$ assez r√©duite pour pouvoir efficacement effectuer des op√©rations alg√©briques : $d << V$, o√π $V est le vocabulaire du corpus √©tudi√©.

#### Les embeddings _context free_

Au sein de ces m√©thodes denses, il s'agit en premier lieu de distinguer les embeddings _context free_ tels que [Glove](https://nlp.stanford.edu/projects/glove/) ou [Word2Vec](https://fr.wikipedia.org/wiki/Word2vec) - la repr√©sentation d'une s√©quence n'est alors qu'une op√©ration sur les mots de la s√©quence.

#### Les transformers comme embeddings _context aware_

Nous distinguons √©galement les embeddings _context aware_, tels que les transformers. Ceux-ci vont, gr√¢ce aux m√©canismes d'attention, d√©tecter par exemple la polys√©mie d'un mot.

Nous pouvons directement utiliser un transformer pr√©entra√Æn√©, sans finetuning, en l'occurrence un mod√®le obtenu par [Semantic Bert](https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models). Le mod√®le pr√©-entra√Æn√© choisi appara√Æt comme √©tant un compromis entre qualit√© de l'output et vitesse d'encoding. En l'occurrence, j'ai choisi  [multi-qa-MiniLM-L6-cos-v1](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1) pour sa l√©g√®ret√© dans le prototypage.


#### Methode sparse ranking/dense reranking

Une m√©thode sparse ranking/dense reranking : la requ√™te est plong√©e dans un espace de repr√©sentation _sparse_ via TF IDF, un premier filtrage est effectu√© sur un top 1000, puis un nouveau scoring est impl√©ment√© au sein d'un espace dense du transformer souhait√© (reranking)

Les m√©thodes d'extraction dense  avec attention font l'objet d'un champ actif de recherche, comme en t√©moigne le challenge [MS Marco pouss√© par Microsoft](https://arxiv.org/pdf/2105.04021.pdf). Le sujet est d'obtenir un compromis entre qualit√© des r√©sultats et vitesse de calcul. La qualit√© du calcul se mat√©rialise par un score d'√©valuation. Une m√©trique telle que le [Mean Reciprocal Rank](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) semble actuellement faire consensus

Similairement, si l'espace de repr√©sentation est important, la mani√®re de calculer la proximit√© entre un document et une requ√™te l'est √©galement. Ce [post](https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7) en propose un tour d'horizon.

### Evaluation par apprentissage/finetuning

Si nous ne sommes pas satisfaits des espaces pr√©-entra√Æn√©s, nous pouvons les affiner en ajustant tout ou partie de leur jeu de param√®tres $\theta$ par un m√©canisme d'apprentissage supervis√©.

Pour ce faire, nous avons classiquemetn besoin d'un jeu d'exemples annot√©s ainsi que d'une fonction de co√ªt. Celle-ci nous permettra de minimiser l'erreur li√©e √† la construction de notre espace de projection. La litt√©rature nous fournit entre autres deux possibilit√©s, impliquant quelques ajustements quant √† la donn√©e d'entra√Ænement. Supposons que l'on dispose de M examples de requ√™tes $q_i$, pour $i \in [[1, M]]$ avec les r√©sultats de documents, positifs et n√©gatifs. 

#### Les _triplet loss_

Les triplets permettent de changer l'espace de repr√©sentation pour rapprocher les √©l√©ments similaires et √©loigner les √©l√©ments dissemblables. La contrepartie est que chaque exemple doit √™tre accompagn√© de deux exemples, l'un positif et l'autre n√©gatif.
 
Une requ√™te $q_i$ est alors qualifi√©e d'_anchor_ (ancre) , $t_{p}^i$ un texte correspondant √† une r√©ponse positive et $t_{n}^i$ une r√©ponse n√©gative. La fonction de co√ªt - √† minimiser en fonction des param√®tres s'√©crit alors :

$$ \mathcal{l}_{\theta}^{T}(q_i, t_{p}^i, t_{n}^i) = max(\left\lVert e_{\theta}(q_i) -  e_{\theta}(t_{p}^i) \right\lVert^2 - \left\lVert  e_{\theta}(q_i) - e_{\theta}(t_{n}^i)  \right\lVert^2, \epsilon)  $$

Le but de l'apprentissage est de trouver le jeu $\theta^*$ de param√®tres satisfaisant : 

$$ \theta^* = \arg\min_{\theta}  \sum_{i=1}^{M}  \mathcal{l}_{\theta}^{T}(q_i, t_{p}^i, t_{n}^i) $$

$\left\lVert.\right\lVert$ est une norme euclidienne, et $\epsilon$ est qualifi√© de _marge_.

Pour chaque example, en fonction de la valeur retourn√©e, nous distinguons trois types de triplets : 

* Easy triplets : ce sont des examples conduisant √† $\mathcal{l}=0$. Ils ne permettent pas un apprentissage ad√©quat
* Hard triplets : ce sont des exemples "contradictoires", dans la mesure o√π la distance de la requ√™te √† l'exemple n√©gatif est inf√©rieur √† la distance √† l'exemple positif
* Semi hard triplets : la loss reste positive car le r√©sultat est ambig√º (dans la marge entre l'exemple positif et l'exemple n√©gatif) 

#### Contrastive Loss

Ici, un exemple d'apprentissage se pr√©sente simplement sous la forme de trois entr√©es : la requ√™te $q_i$, un exemple de document $t_i$, et un label $y_i$ siginifiant si l'exemple est n√©gatif ($y_i=0$) ou positif ($y_i=1$).

Cette loss - appelons la $\mathcal{l}_{\theta}^{C}$  - s'√©crit alors : 


$$ \mathcal{l}_{\theta}^{C}(q_i, t_i, y_i) = y_i\mathcal{l}_{\theta}^{+}(q_i, t_i)+ (1 - y_i)\mathcal{l}_{\theta}^{-}(q_i, t_i, \epsilon)   $$

Cette fonction prendra donc une forme diff√©rente selon si l'exemple est n√©gatif ou positif. Nous allons nous aider de la fonction auxiliaire $E$, qui n'est autre qu'un produit scalaire normalis√©. Il s'agit d'une d√©finition de la similarit√© cosine : 

$$ E(x,y) =  \frac{ <x,y> }{\left\lVert x \right\lVert \left\lVert y \right\lVert}  $$

| Cas positif | Cas n√©gatif |
|-------------|-------------|
| $$ \mathcal{l}_{\theta}^{+}(q_i, t_i) = \frac{1}{4}(1 - E(e_{\theta}(q_i), e_{\theta}(t_i))) $$ | $$ \mathcal{l}_{\theta}^{-}(q_i, t_i, \epsilon) = E(e_{\theta}(q_i), e_{\theta}(t_i))^{2}\mathbb{1}_{E(e_{\theta}(q_i), e_{\theta}(t_i))<\epsilon} $$ |

Ainsi, cette fonction de co√ªt s'apprend de la m√™me mani√®re que pr√©c√©demment : 

$$ \theta^* = \arg\min_{\theta}  \sum_{i=1}^{M}  \mathcal{l}_{\theta}^{C}(q_i, t_i) $$

## Ing√©nierie : pistes d'industrialisation (en cours üöß üöß üöß)

 La profondeur de la base de donn√©es utilis√©e pour la maquette pour ce prototype est assez faible pour encore impl√©menter un moteur industrialisable. N√©anmoins, quelques pistes peuvent √™tre sugg√©r√©es en guise d'industrialisation.

#### Pistes d'indexation scalable.

L'indexation consiste √† relier une s√©quence √©ligible √† la recherche en un vecteur requ√™table par suite.

Au sein des m√©thodes d'extraction sparse, une foultitude d'autres possibilit√©s que le TF IDF existe. En l'occurrence, Elastic utilise par d√©faut [BM25](https://www.elastic.co/fr/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)
Evoquons un instant les m√©thodes d'indexation et/ou de requ√™tage. En effet, si, dans notre cas, les index (ce qui va effectivement relier un document √† sa repr√©sentation) cr√©√©s sont de taille relativement faible, dans la pratique, une op√©ration comparant une requ√™te utilisateur √† des millions, voire des millards d'entit√©s se trouve √™tre un challenge technique d'envergure. Le logiciel [ElasticSearch](https://www.elastic.co/fr/elasticsearch/) est une r√©ussite en ce qui concerne la scalabilit√©. 


Une m√©thode d'indexation efficace peut se faire √† l'aide de [FAISS](https://github.com/facebookresearch/faiss).

### Consid√©rations d'infrastructure : de l'utilit√© du cloud

Pour des raisons d'√©lasticit√©, autant lors de la formation du mod√®le que lors de la mise √† disposition des requ√™tes, nous pouvons utiliser √† profit les utilitaires du cloud. Par exemple, la donn√©e peut √™tre heberg√©e dans un bucket AWS S3 : la visite d'un utilisateur et sa requ√™te enclenchent AWS Lambda, qui lui-m√™me appelle un [endpoint SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html), contenant le mod√®le en production. Suivant le mod√®le utilis√© et/ou la taille de la base de donn√©es, cet endpoint peut s'appuyer sur des instances plus ou moins puissantes en termes de capacit√© de calcul


## Quelques ressources

* Bien s√ªr, il y a le n√©cessaire [blog de Jay Alammar](https://jalammar.github.io/illustrated-bert/) pour comprendre BERT et les Transformers.
* Elastic.co fait un excellent travail didactique de pr√©sentation du _revelance scoring_ ([ici](https://www.elastic.co/fr/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch) et [l√†](https://www.elastic.co/fr/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)
* Cet [article du MIT](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00369/100684/Sparse-Dense-and-Attentional-Representations-for) formalise non seulement de mani√®re tr√®s rigoureuse le requ√™tage de textes, mais conduit √©galement une √©tude exhaustive des possibilit√©s.
* Sur les fonctions de co√ªt permettant d'appr√©hender la similarit√© : [triplet loss](https://arxiv.org/pdf/1503.03832.pdf) et [contrastive loss](https://aclanthology.org/W16-1617.pdf)
